{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f8458f-6883-4dd9-a104-9e1399d909d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "tqdm.pandas()\n",
    "from io import StringIO\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5445c467-0069-4229-9c15-e0cd8697fb61",
   "metadata": {},
   "source": [
    "## загружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a519f5-cb18-41af-9ece-ca04deac01ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "S3_KEY_ID = os.environ.get(\"S3_KEY_ID\")\n",
    "S3_SECRET_KEY = os.environ.get(\"S3_SECRET_KEY\")\n",
    "S3_BUCKET = os.environ.get(\"S3_BUCKET\")\n",
    "BUCKET_DIR = \"splitted_data/\"\n",
    "FILENAME = \"splitted_df_3000.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b791116e-6139-4ff8-8f24-0ad399713e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.session.Session()\n",
    "s3 = session.client(\n",
    "    service_name=\"s3\",\n",
    "    endpoint_url=\"https://storage.yandexcloud.net\",\n",
    "    aws_access_key_id=S3_KEY_ID,\n",
    "    aws_secret_access_key=S3_SECRET_KEY,\n",
    "    region_name=\"ru-cental1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a46e72-332f-4fb3-a0bc-568b6cf85afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_obj = s3.get_object(Bucket=S3_BUCKET, Key=BUCKET_DIR + FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7877a5e4-a4b6-4047-a7cc-276feb612d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(StringIO(csv_obj[\"Body\"].read().decode(\"utf-8\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41476664-7b80-44b6-9260-5373ecb1f53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt2name = {\n",
    "    \"author_id_00\": \"А. Пушкин\",\n",
    "    \"author_id_01\": \"Д. Мамин-Сибиряк\",\n",
    "    \"author_id_02\": \"И. Тургенев\",\n",
    "    \"author_id_03\": \"А. Чехов\",\n",
    "    \"author_id_04\": \"Н. Гоголь\",\n",
    "    \"author_id_05\": \"И. Бунин\",\n",
    "    \"author_id_06\": \"А. Куприн\",\n",
    "    \"author_id_07\": \"А. Платонов\",\n",
    "    \"author_id_08\": \"В. Гаршин\",\n",
    "    \"author_id_09\": \"Ф. Достоевский\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6930fb5-ac24-4c75-a4b0-265a59276e68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# замена значений столбца target фамилиями авторов\n",
    "df.replace(tgt2name, inplace=True)\n",
    "\n",
    "df.head()\n",
    "\n",
    "# вывод на экран первого текста\n",
    "print(df.target[0])\n",
    "print(df.book[0])\n",
    "print(df.text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dfcf2b-1a7d-48e5-bfeb-03526fd99ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"rus_authors.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659e1d30-6bf9-4718-a068-a46198086f01",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc5f03c-0c75-4a68-91d1-42eec2520699",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    max_new_tokens=512,\n",
    "    do_sample=True,\n",
    "    num_beams=1,\n",
    "    temperature=0.25,\n",
    "    top_k=50,\n",
    "    top_p=0.98,\n",
    "    eos_token_id=79097,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1e3e0f-2e53-4396-ae95-1c8c59f8f930",
   "metadata": {},
   "source": [
    "### saiga_llama3_8b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd8dbce-46d0-4150-a557-01e9e9908ae8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"IlyaGusev/saiga_llama3_8b\",\n",
    "    device_map=\"auto\",\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"IlyaGusev/saiga_llama3_8b\")\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4691b7a-8db7-4086-8478-4803d389a827",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SYSTEM_PROMPT = \"Ты получишь тексты, принадлежащие русским писателям 19 века - А. Пушкину, Д. Мамин-Сибиряку, И. Тургеневy, А. Чехову, Н. Гоголю, И. Бунину, А. Куприну, А. Платонову, В. Гаршину, Ф. Достоевскому. Напиши кому из них принадлежит каждый текст, текстов других писателей не будет\"\n",
    "\n",
    "df[\"saiga_author\"] = None\n",
    "df[\"saiga_process_time\"] = None\n",
    "\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    t_start = time.time()\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": DEFAULT_SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": row[\"text\"]},\n",
    "        ],\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "    output = pipe(prompt, **config)\n",
    "    output = output[0][\"generated_text\"][len(prompt) :].strip()\n",
    "\n",
    "    df.at[i, \"saiga_author\"] = output\n",
    "    df.at[i, \"saiga_process_time\"] = time.time() - t_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f3a885-3a70-4165-a061-d668c673feca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460eff25-c27e-4a3f-81f6-9071bbb1ef59",
   "metadata": {},
   "source": [
    "### Vikhr-7B-instruct_0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41be72ae-c4d3-47bf-a270-b428890ba2b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"Vikhrmodels/Vikhr-7B-instruct_0.4\",\n",
    "    device_map=\"auto\",\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Vikhrmodels/Vikhr-7B-instruct_0.4\")\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cac3b93-28cf-42c1-8e02-fe60daebac55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"vikhr_author\"] = None\n",
    "df[\"vikhr_process_time\"] = None\n",
    "\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    t_start = time.time()\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": DEFAULT_SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": row[\"text\"]},\n",
    "        ],\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "    output = pipe(prompt, **config)\n",
    "    output = output[0][\"generated_text\"][len(prompt) :].strip()\n",
    "\n",
    "    df.at[i, \"vikhr_author\"] = output\n",
    "    df.at[i, \"vikhr_process_time\"] = time.time() - t_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93eef374-29e5-4d00-a590-d6f414024889",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d212ef3-74b6-4087-b832-9061e3492aee",
   "metadata": {},
   "source": [
    "### Meta-Llama-3-8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6545ed-e55f-4872-b372-af782185ff55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Meta-Llama-3-8B\",\n",
    "    device_map=\"auto\",\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B\")\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e26b0c-3707-4702-91bf-ac66325ac4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"vikhr_author\"] = None\n",
    "df[\"vikhr_process_time\"] = None\n",
    "\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    t_start = time.time()\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": DEFAULT_SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": row[\"text\"]},\n",
    "        ],\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "    output = pipe(prompt, **config)\n",
    "    output = output[0][\"generated_text\"][len(prompt) :].strip()\n",
    "\n",
    "    df.at[i, \"vikhr_author\"] = output\n",
    "    df.at[i, \"vikhr_process_time\"] = time.time() - t_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81309277-c5d5-4d30-8667-c36515238fd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"llama_author\"] = None\n",
    "df[\"llama_process_time\"] = None\n",
    "\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    t_start = time.time()\n",
    "\n",
    "    # if row['num_repr_texts'] < 4:\n",
    "    #     output = row['repr_text']\n",
    "    # else:\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        [\n",
    "            {\"role\": \"system\", \"content\": DEFAULT_SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": row[\"text\"]},\n",
    "        ],\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "    output = pipe(prompt, **config)\n",
    "    print(output)\n",
    "    output = output[0][\"generated_text\"][len(prompt) :].strip()\n",
    "\n",
    "df.at[i, \"llama_author\"] = output\n",
    "df.at[i, \"llama_process_time\"] = time.time() - t_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2a7de8-6feb-440c-9734-b7aed9cdc500",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7903e4a0-4137-40a5-9bcf-58457944430e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}