{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67846fd3-7b6b-45d5-93ac-d1813f58bdec",
   "metadata": {},
   "source": [
    "# импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc361f77-47ae-4cd8-95d3-69c42644468c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Applications/PyCharm.app/Contents/plugins/python/helpers-pro/jupyter_debug', '/Applications/PyCharm.app/Contents/plugins/python/helpers/pydev', '/Users/dariamishina/Documents/HSE/YearProject/mlds23-authorship-identification/data_preproc/notebooks', '/Users/dariamishina/Documents/HSE/YearProject', '/Users/dariamishina/.conda/envs/untitled/lib/python38.zip', '/Users/dariamishina/.conda/envs/untitled/lib/python3.8', '/Users/dariamishina/.conda/envs/untitled/lib/python3.8/lib-dynload', '', '/Users/dariamishina/.conda/envs/untitled/lib/python3.8/site-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# добавляем в path папку с тем файлом, откуда надо импортировать функции\n",
    "sys.path.append('/Users/dariamishina/Documents/HSE/YearProject/mlds23-authorship-identification')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/dariamishina/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dariamishina/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from data_preproc.src.utils import text_splitter"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# sys.path.remove('/Users/dariamishina/Documents/HSE/YearProject/mlds23-authorship-identification')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "507900b5-1acd-4433-953a-447a7f8e3b7f",
   "metadata": {},
   "source": [
    "# загружаем тексты из s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d43ddcc-06f3-4d79-bbf3-335f7b2f742d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = 'mlds23-authorship-identification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e92278-f8b0-4d46-82d2-f19da9c6a417",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.session.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1a4be0-c35a-42c9-8683-3b3b9b7458df",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = session.client(\n",
    "    service_name='s3',\n",
    "    endpoint_url='https://storage.yandexcloud.net',\n",
    "    aws_access_key_id='YCAJE6bQjBm5o7PaMjYqDKLFT',\n",
    "    aws_secret_access_key='YCOVpYeJO8yux1IROpFDoGLkXxKZAIIrAdU0bZZ6',\n",
    "    region_name='ru-cental1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f3b19d-dfbd-4f84-9706-ed56542fe445",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in s3.list_objects(Bucket=BUCKET_NAME)['Contents']:\n",
    "    print(key['Key'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b1143d-2003-4d84-92a8-31a49c0d4235",
   "metadata": {},
   "source": [
    "# загружаем и сразу же сплиттим на токены"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fcb8ae-d4ec-41d8-a5ef-a7aa11de1fbd",
   "metadata": {},
   "source": [
    "Идея от Лены как разбивать произведения\n",
    "\n",
    "1) Токенизировать nltk/spacy\n",
    "2) Идем по списку токенов, как только набрали например 550 (это кстати точно гораздо больше, чем 5 предложений) — отрезаем все, которые были после последней запятой/точки/т.д. Т.е. если встреченный токен — пунктуация, то храним его индекс, потом срез до него"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61eff8aa-e67e-4b7a-8ed7-b430eeb94b8d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "total_df = []\n",
    "for key in s3.list_objects(Bucket=BUCKET_NAME)['Contents']:\n",
    "    try:\n",
    "        if 'txt' in key['Key']: #фильтруем по расширению файла, нужны только txt\n",
    "            file = s3.get_object(Bucket=BUCKET_NAME,Key=key['Key'])['Body']\n",
    "            text = file.read().decode(\"utf-8\")\n",
    "            df = text_splitter(text) #вызываем функцию из utils для сплитования\n",
    "            df['book'] = key['Key'] #добавляем название произведения в отдельный столбец\n",
    "            total_df.append(df)\n",
    "    except:\n",
    "        print('не тот файл', key['Key'])\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b31265-b687-49e7-be43-39746319de94",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = pd.concat(total_df)\n",
    "total_df.reset_index(drop=True, inplace=True)\n",
    "total_df.to_csv('splitted_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2167a087-de5c-4ff2-9518-f6f0b1647156",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/home/d-mishina/texts/' #это локальный путь! Куда сохранился мой csv файл\n",
    "DF_FILE_NAME = 'splitted_df.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22da9aa-4bd2-4427-be34-110e6f748716",
   "metadata": {},
   "source": [
    "# загружаем в s3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d721e6-2e3e-4f7e-a624-4beef8f53dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.upload_file(f'{DATA_PATH}{DF_FILE_NAME}', BUCKET_NAME, f'splitted_data/{DF_FILE_NAME}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}