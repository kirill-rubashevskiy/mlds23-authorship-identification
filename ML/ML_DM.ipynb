{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from tqdm import trange\n",
    "from nltk import tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.probability import FreqDist\n",
    "from collections import Counter\n",
    "\n",
    "my_stopwords = [] #заглушка если придумаем стопслова\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "russian_stopwords_new = stopwords.words(\"russian\")\n",
    "russian_stopwords_new.extend(my_stopwords)\n",
    "not_stopwords = {'не', 'ни'}\n",
    "russian_stopwords = [word for word in russian_stopwords_new if word not in not_stopwords]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/dariamishina/Documents/HSE/YearProject/mlds23-authorship-identification/ML', '/Users/dariamishina/.conda/envs/untitled/lib/python38.zip', '/Users/dariamishina/.conda/envs/untitled/lib/python3.8', '/Users/dariamishina/.conda/envs/untitled/lib/python3.8/lib-dynload', '', '/Users/dariamishina/.conda/envs/untitled/lib/python3.8/site-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# добавляем в path папку с тем файлом, откуда надо импортировать функции\n",
    "sys.path.append('/Users/dariamishina/Documents/HSE/YearProject/mlds23-authorship-identification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/dariamishina/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/dariamishina/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from data_preproc.src.utils import preprocess_text1, preprocess_text2, preprocess_text3, preprocess_text4, tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.session.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = session.client(\n",
    "    service_name='s3',\n",
    "    endpoint_url='https://storage.yandexcloud.net',\n",
    "    aws_access_key_id='YCAJErlaldUmioGbHQSqJ70MR',\n",
    "    aws_secret_access_key='YCPSba_JgloNYSNWcnKO2CYCEB8PFR1Iwgr2jIUy',\n",
    "    region_name='ru-cental1'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем уже расспличенные тексты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"mlds23-authorship-identification\"\n",
    "BUCKET_DIR = \"splitted_data/\"\n",
    "FILENAME = 'splitted_df.csv'\n",
    "#загружает в локальную директорию, потом отдельно надо считывать\n",
    "s3.download_file(Filename=FILENAME, Bucket=BUCKET_NAME, Key=BUCKET_DIR + FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('splitted_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>book</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>author_id_06</td>\n",
       "      <td>Узкими горными тропинками , от одного дачного ...</td>\n",
       "      <td>raw_data/aleksandr_kuprin_belyj_pudel'.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>author_id_06</td>\n",
       "      <td>свернутый ковер для акробатических упражнений ...</td>\n",
       "      <td>raw_data/aleksandr_kuprin_belyj_pudel'.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>author_id_06</td>\n",
       "      <td>позабытые . Кроме того , были в шарманке две п...</td>\n",
       "      <td>raw_data/aleksandr_kuprin_belyj_pudel'.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>author_id_06</td>\n",
       "      <td>тайной грусти : — Что поделаешь ? .. Древний о...</td>\n",
       "      <td>raw_data/aleksandr_kuprin_belyj_pudel'.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>author_id_06</td>\n",
       "      <td>, да уж ладно ! Кормила она нас с тобой , Серг...</td>\n",
       "      <td>raw_data/aleksandr_kuprin_belyj_pudel'.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target                                               text  \\\n",
       "0  author_id_06  Узкими горными тропинками , от одного дачного ...   \n",
       "1  author_id_06  свернутый ковер для акробатических упражнений ...   \n",
       "2  author_id_06  позабытые . Кроме того , были в шарманке две п...   \n",
       "3  author_id_06  тайной грусти : — Что поделаешь ? .. Древний о...   \n",
       "4  author_id_06  , да уж ладно ! Кормила она нас с тобой , Серг...   \n",
       "\n",
       "                                         book  \n",
       "0  raw_data/aleksandr_kuprin_belyj_pudel'.txt  \n",
       "1  raw_data/aleksandr_kuprin_belyj_pudel'.txt  \n",
       "2  raw_data/aleksandr_kuprin_belyj_pudel'.txt  \n",
       "3  raw_data/aleksandr_kuprin_belyj_pudel'.txt  \n",
       "4  raw_data/aleksandr_kuprin_belyj_pudel'.txt  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Выделяем классы метками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = LabelEncoder()\n",
    "df['author_id'] = enc.fit_transform(df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author_id\n",
       "1     379\n",
       "7     446\n",
       "8     627\n",
       "5     725\n",
       "3     804\n",
       "6    1047\n",
       "4    1295\n",
       "0    1299\n",
       "9    2387\n",
       "2    2706\n",
       "Name: author_id, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#посмотрим на распределение классов\n",
    "df.groupby('author_id').author_id.count().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# подготовка для TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#используем самую \"суровую предобработку\" с лемматизацией\n",
    "df['text_proc1'] = df['text'].apply(lambda x: preprocess_text1(x, tostr=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>book</th>\n",
       "      <th>author_id</th>\n",
       "      <th>text_proc1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>author_id_06</td>\n",
       "      <td>Узкими горными тропинками , от одного дачного ...</td>\n",
       "      <td>raw_data/aleksandr_kuprin_belyj_pudel'.txt</td>\n",
       "      <td>6</td>\n",
       "      <td>узкий горный тропинка дачный поселок пробирать...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>author_id_06</td>\n",
       "      <td>свернутый ковер для акробатических упражнений ...</td>\n",
       "      <td>raw_data/aleksandr_kuprin_belyj_pudel'.txt</td>\n",
       "      <td>6</td>\n",
       "      <td>свернутый ковер акробатический упражнение прав...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>author_id_06</td>\n",
       "      <td>позабытые . Кроме того , были в шарманке две п...</td>\n",
       "      <td>raw_data/aleksandr_kuprin_belyj_pudel'.txt</td>\n",
       "      <td>6</td>\n",
       "      <td>позабывать кроме шарманка предательский труба ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>author_id_06</td>\n",
       "      <td>тайной грусти : — Что поделаешь ? .. Древний о...</td>\n",
       "      <td>raw_data/aleksandr_kuprin_belyj_pudel'.txt</td>\n",
       "      <td>6</td>\n",
       "      <td>тайный грусть   —  поделать древний орган прос...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>author_id_06</td>\n",
       "      <td>, да уж ладно ! Кормила она нас с тобой , Серг...</td>\n",
       "      <td>raw_data/aleksandr_kuprin_belyj_pudel'.txt</td>\n",
       "      <td>6</td>\n",
       "      <td>ладно кормить сергей сей пора бог давать покор...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target                                               text  \\\n",
       "0  author_id_06  Узкими горными тропинками , от одного дачного ...   \n",
       "1  author_id_06  свернутый ковер для акробатических упражнений ...   \n",
       "2  author_id_06  позабытые . Кроме того , были в шарманке две п...   \n",
       "3  author_id_06  тайной грусти : — Что поделаешь ? .. Древний о...   \n",
       "4  author_id_06  , да уж ладно ! Кормила она нас с тобой , Серг...   \n",
       "\n",
       "                                         book  author_id  \\\n",
       "0  raw_data/aleksandr_kuprin_belyj_pudel'.txt          6   \n",
       "1  raw_data/aleksandr_kuprin_belyj_pudel'.txt          6   \n",
       "2  raw_data/aleksandr_kuprin_belyj_pudel'.txt          6   \n",
       "3  raw_data/aleksandr_kuprin_belyj_pudel'.txt          6   \n",
       "4  raw_data/aleksandr_kuprin_belyj_pudel'.txt          6   \n",
       "\n",
       "                                          text_proc1  \n",
       "0  узкий горный тропинка дачный поселок пробирать...  \n",
       "1  свернутый ковер акробатический упражнение прав...  \n",
       "2  позабывать кроме шарманка предательский труба ...  \n",
       "3  тайный грусть   —  поделать древний орган прос...  \n",
       "4  ладно кормить сергей сей пора бог давать покор...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df['text_proc1'], df['author_id'], test_size = 0.3, random_state=42,\\\n",
    "                                                    stratify=df['author_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_model(x_train, y_train):\n",
    "    \n",
    "    tf_idf = TfidfVectorizer(stop_words=russian_stopwords, max_features=550, min_df=2)\n",
    "    \n",
    "    logit = LogisticRegression(C=1e2, n_jobs=4, solver='sag', #solver='lbfgs', #проблема с этим солвером\n",
    "                           random_state=42, verbose=0, \n",
    "                           multi_class='multinomial',\n",
    "                           fit_intercept=True, max_iter=400)\n",
    "   \n",
    "    tfidf_logit_pipeline = Pipeline([('tf_idf', tf_idf), \n",
    "                                 ('logit', logit)])\n",
    "    tfidf_logit_pipeline.fit(x_train, y_train)\n",
    "    return tfidf_logit_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_logit_pipeline = tfidf_model(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 151 ms, sys: 7.26 ms, total: 158 ms\n",
      "Wall time: 188 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = tfidf_logit_pipeline.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.590514812375762"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6364153627311522"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6364694242915129"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}